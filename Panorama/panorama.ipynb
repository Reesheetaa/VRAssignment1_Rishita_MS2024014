{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def stitch_two_images(img1, img2):\n",
    "    \n",
    "    # Grayscale\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    # Detecting SIFT features\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(gray1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(gray2, None)\n",
    "    \n",
    "    \n",
    "    # Matching features\n",
    "    matcher = cv2.BFMatcher()\n",
    "    raw_matches = matcher.knnMatch(des1, des2, k=2)\n",
    "   \n",
    "    \n",
    "    # Filtering matches using Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for m, n in raw_matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    print(f\"Found {len(good_matches)} good matches\")\n",
    "    \n",
    "    if len(good_matches) < 4:\n",
    "        raise Exception(\"Not enough good matches for homography\")\n",
    "    \n",
    "    # Extracting location of good matches\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Finding homography matrix\n",
    "    H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    \n",
    "    if H is None:\n",
    "        raise Exception(\"Could not find homography\")\n",
    "    \n",
    "    H = H.astype(np.float32)\n",
    "    \n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    \n",
    "    \n",
    "    # Image2\n",
    "    corners2 = np.array([\n",
    "        [0, 0],\n",
    "        [0, h2-1],\n",
    "        [w2-1, h2-1],\n",
    "        [w2-1, 0]\n",
    "    ], dtype=np.float32).reshape(-1, 1, 2)\n",
    "    \n",
    "    corners2_transformed = cv2.perspectiveTransform(corners2, H)\n",
    "        \n",
    "    # Image1\n",
    "    corners1 = np.array([\n",
    "        [0, 0],\n",
    "        [0, h1-1],\n",
    "        [w1-1, h1-1],\n",
    "        [w1-1, 0]\n",
    "    ], dtype=np.float32).reshape(-1, 1, 2)\n",
    "    \n",
    "    \n",
    "    all_corners = np.concatenate((corners1, corners2_transformed), axis=0)\n",
    "    x_min, y_min = np.int32(all_corners.min(axis=0).ravel())\n",
    "    x_max, y_max = np.int32(all_corners.max(axis=0).ravel())\n",
    "    \n",
    "    \n",
    "    translation = np.array([\n",
    "        [1, 0, -x_min],\n",
    "        [0, 1, -y_min],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Combined transformation\n",
    "    H_with_translation = translation @ H\n",
    "    \n",
    "    output_width = x_max - x_min + 1\n",
    "    output_height = y_max - y_min + 1\n",
    "    output_shape = (output_width, output_height)\n",
    "    \n",
    "    warped_img2 = cv2.warpPerspective(img2, H_with_translation, output_shape)\n",
    "    \n",
    "    warped_img1 = cv2.warpPerspective(img1, translation, output_shape)\n",
    "    \n",
    "    \n",
    "    # Creating masks for blending\n",
    "    mask1 = (warped_img1 > 0).astype(np.uint8)\n",
    "    mask2 = (warped_img2 > 0).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    # Creating a weight map for blending\n",
    "    overlap = mask1 * mask2\n",
    "    weight1 = np.zeros_like(warped_img1, dtype=np.float32)\n",
    "    weight2 = np.zeros_like(warped_img2, dtype=np.float32)\n",
    "    \n",
    "    for y in range(output_height):\n",
    "        for x in range(output_width):\n",
    "            if overlap[y, x].any():\n",
    "                weight1[y, x] = 1 - (x / output_width)\n",
    "                weight2[y, x] = x / output_width\n",
    "            else:\n",
    "                if mask1[y, x].any():\n",
    "                    weight1[y, x] = 1\n",
    "                if mask2[y, x].any():\n",
    "                    weight2[y, x] = 1\n",
    "    \n",
    "    # Normalizing weights\n",
    "    weight_sum = weight1 + weight2\n",
    "    weight_sum[weight_sum == 0] = 1  \n",
    "    weight1 /= weight_sum\n",
    "    weight2 /= weight_sum\n",
    "    \n",
    "    \n",
    "    # Blending the images\n",
    "    result = np.zeros_like(warped_img1, dtype=np.float32)\n",
    "    for c in range(3):  # Blending each channel separately\n",
    "        result[:, :, c] = (warped_img1[:, :, c] * weight1[:, :, c] +\n",
    "                           warped_img2[:, :, c] * weight2[:, :, c])\n",
    "    \n",
    "    result = np.clip(result, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    # Creating visualizations\n",
    "    output_dir = Path(\"panorama_output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Saving visualization of the keypoint matches\n",
    "    match_img = cv2.drawMatches(img1, kp1, img2, kp2, good_matches[:50], None, \n",
    "                              flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.imwrite(str(output_dir / \"matches_detail.jpg\"), match_img)\n",
    "    \n",
    "    # Saving individual keypoint visualizations\n",
    "    kp_img1 = cv2.drawKeypoints(img1, kp1, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    kp_img2 = cv2.drawKeypoints(img2, kp2, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    cv2.imwrite(str(output_dir / \"keypoints_img1.jpg\"), kp_img1)\n",
    "    cv2.imwrite(str(output_dir / \"keypoints_img2.jpg\"), kp_img2)\n",
    "    \n",
    "    # Saving intermediate warped images\n",
    "    cv2.imwrite(str(output_dir / \"warped_img1.jpg\"), warped_img1)\n",
    "    cv2.imwrite(str(output_dir / \"warped_img2.jpg\"), warped_img2)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitching first two images...\n",
      "Found 278 good matches\n",
      "Saved panorama to final_output\\panorama.jpg\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    output_dir = Path(\"final_output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    \n",
    "    image_paths = [\n",
    "        \"images2/panorama12.jpg\",\n",
    "        \"images2/panorama34.jpg\",\n",
    "    ]\n",
    "    \n",
    "    valid_paths = []\n",
    "    for path in image_paths:\n",
    "        if os.path.exists(path):\n",
    "            valid_paths.append(path)\n",
    "        else:\n",
    "            print(f\"Warning: Image file {path} not found\")\n",
    "    \n",
    "    if len(valid_paths) < 2:\n",
    "        print(\"Need at least 2 valid images for stitching\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    images = []\n",
    "    for path in valid_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {path}\")\n",
    "            continue\n",
    "        images.append(img)\n",
    "    \n",
    "    if len(images) < 2:\n",
    "        print(\"Need at least 2 valid images for stitching\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print(\"Stitching first two images...\")\n",
    "        panorama = stitch_two_images(images[0], images[1])\n",
    "        cv2.imwrite(str(output_dir / \"panorama.jpg\"), panorama)\n",
    "        print(f\"Saved panorama to {output_dir / 'panorama.jpg'}\")\n",
    "        \n",
    "        result = panorama\n",
    "        for i in range(2, len(images)):\n",
    "            print(f\"Stitching image {i+1} to the panorama...\")\n",
    "            result = stitch_two_images(result, images[i])\n",
    "            cv2.imwrite(str(output_dir / f\"panorama_with_{i+1}_images.jpg\"), result)\n",
    "            print(f\"Saved updated panorama to {output_dir / f'panorama_with_{i+1}_images.jpg'}\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "        for i, img in enumerate(images):\n",
    "            if len(images) > 1:\n",
    "                ax = axes[i]\n",
    "            else:\n",
    "                ax = axes\n",
    "            ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"Input {i+1}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / \"input_images.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Final Panorama\")\n",
    "        plt.savefig(output_dir / \"final_panorama_visualization.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in panorama stitching: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
